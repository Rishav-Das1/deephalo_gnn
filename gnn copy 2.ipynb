{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_max_pool, knn_graph\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "# Set seed\n",
    "# SEED=42\n",
    "# random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11989"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PointNetInstanceSeg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetInstanceSeg, self).__init__()\n",
    "        self.edge_conv1 = DynamicEdgeConv(nn.Sequential(\n",
    "            nn.Linear(14, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.SiLU()\n",
    "        ), k=K)\n",
    "        self.fc = nn.Linear(128, 21)  # Predicting instance mask for each point\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.pos, data.edge_index\n",
    "        x = self.edge_conv1(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Calc number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(PointNetInstanceSeg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have point cloud data stored as a list of positions\n",
    "data = \"/home/group10/deephalo_gnn/Imbalance_Resampled_for_mulltilabel/train\"\n",
    "files = os.listdir(data)\n",
    "point_cloud_data = [(np.load(data+\"/\"+f)) for f in files if f.endswith(\".npy\")] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the positions of points\n",
    "    pos = torch.tensor(point_cloud[:,:-1], dtype=torch.float)\n",
    "    # Recentering positions per halo\n",
    "    pos[:3] = pos[:3] - pos[:3].mean(dim=1, keepdim=True)\n",
    "    data = Data(\n",
    "        pos=pos,\n",
    "        y = torch.eye(21)[torch.tensor(point_cloud[:,-1]+1, dtype=torch.long)],\n",
    "        # edge_index=knn_graph(pos, k=K)\n",
    "    )\n",
    "    # data.y = torch.tensor(point_cloud[:,-1], dtype=torch.long)\n",
    "    # Dynamically generate edge_index based on the positions of points\n",
    "    # You can use a method like k-NN to construct the edges\n",
    "    # For example, using knn_graph from torch_geometric.transforms:\n",
    "    # from torch_geometric.transforms import knn_graph\n",
    "    # data.edge_index = knn_graph(data.pos, k=K)  # Construct edges based on 6 nearest neighbors\n",
    "    # Add other necessary attributes to the Data object if needed\n",
    "    # For example, data.y for ground truth labels\n",
    "    data_list.append(data)\n",
    "\n",
    "# Now you can use DataLoader with this list of Data objects\n",
    "loader = DataLoader(data_list, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([0, 0, 0,  ..., 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "data.y\n",
    "print(data.y)\n",
    "class_labels = torch.argmax(data.y, dim=1)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for point_clouds in point_cloud_data:\n",
    "    label = point_clouds[:,-1]\n",
    "    labels.append(label)\n",
    "labels = torch.tensor(np.concatenate(labels))\n",
    "# Convert list of tensors to a single tensor\n",
    "# labels = torch.cat(labels)\n",
    "\n",
    "# Calculate unique labels and counts\n",
    "unique_labels, counts = torch.unique(labels, return_counts=True)\n",
    "\n",
    "# Calculate frequencies\n",
    "frequencies = counts.float() / labels.numel()\n",
    "\n",
    "# Calculate weights\n",
    "weight_vec = 1.0 / torch.log(torch.tensor(1.2) + frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vec[0]=0.01\n",
    "weight_vec\n",
    "weight_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1., gamma=2.):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce_logits = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = self.bce_logits(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group10/deephalo_gnn/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Define your dataset and DataLoader\n",
    "# dataloader = DataLoader(SHDataSet(\"train\"), batch_size=1, shuffle=True)\n",
    "# Initialize the model\n",
    "model = PointNetInstanceSeg().to(DEVICE)\n",
    "weights = torch.FloatTensor(weight_vec).to(DEVICE)\n",
    "# Define your loss function and optimizer\n",
    "# Assuming instance masks are represented as class labels\n",
    "\n",
    "criterion = FocalLoss(alpha=weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 102/102 [00:27<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 248.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 102/102 [00:27<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 86.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 102/102 [00:27<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 64.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 102/102 [00:27<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 47.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 102/102 [00:27<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 50.4105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 102/102 [00:27<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 39.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 102/102 [00:27<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 30.3453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 102/102 [00:27<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 23.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 102/102 [00:27<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 21.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 102/102 [00:27<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 15.9767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        #try:\n",
    "        # print(data.pos.shape, data.pos.size(0), data.pos.numel())\n",
    "        # assert 2 == 3\n",
    "        # x.size(0) == batch_x.numel()\n",
    "        data.to(DEVICE)\n",
    "        # print(data.y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        # Assuming instance masks are represented as class labels and provided in data.y\n",
    "        # target = torch.argmax(data.y, dim=1)  # Convert one-hot encoded target to class labels\n",
    "        # Resize or reshape tensors to match sizes\n",
    "        loss = criterion(outputs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Create the \"ckpts\" directory if it doesn't exist\n",
    "import os, time\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "curr_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"{curr_time}_pointnet_instance_seg\"\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f\"./ckpts/{model_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = \"/home/group10/deephalo_gnn/New test\"\n",
    "files = os.listdir(data_test)\n",
    "point_cloud_data = [(np.load(data_test+\"/\"+f)) for f in files if f.endswith(\".npy\") and (int(f[:-4])>50)] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_test_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the positions of points\n",
    "    data_test = Data(pos=torch.tensor(point_cloud[:,:-1], dtype=torch.float), y = torch.eye(21)[torch.tensor(point_cloud[:,-1]+1, dtype=torch.long)])\n",
    "    # data.y = torch.tensor(point_cloud[:,-1], dtype=torch.long)\n",
    "    # Dynamically generate edge_index based on the positions of points\n",
    "    # You can use a method like k-NN to construct the edges\n",
    "    # For example, using knn_graph from torch_geometric.transforms:\n",
    "    # from torch_geometric.transforms import knn_graph\n",
    "    # data.edge_index = knn_graph(data.pos, k=6)  # Construct edges based on 6 nearest neighbors\n",
    "    # Add other necessary attributes to the Data object if needed\n",
    "    # For example, data.y for ground truth labels\n",
    "    data_test_list.append(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"./ckpts/{model_name}_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 23/23 [00:00<00:00, 100.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a DataLoader `test_loader` for your test data\n",
    "test_loader = DataLoader(data_test_list, batch_size=1, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "\n",
    "# if not model_name:\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions\n",
    "ground_truth_labels = []\n",
    "predictions = []\n",
    "pos_list = []\n",
    "\n",
    "# Loop over the test data\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        # Move data to the device\n",
    "        data = data.to(DEVICE)\n",
    "\n",
    "        # Pass the data through the model\n",
    "        outputs = model(data)\n",
    "        pos = data.pos.cpu().numpy()\n",
    "\n",
    "        pos_list.append(pos)\n",
    "        # Get the predicted labels\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        _, ground_truth = torch.max(data.y, 1)\n",
    "        # Store the predictions\n",
    "        ground_truth_labels.append(ground_truth.cpu().numpy())\n",
    "        predictions.append(predicted_labels.cpu().numpy())\n",
    "\n",
    "\n",
    "# At this point, `predictions` is a list of numpy arrays with the predicted labels for each point cloud in the test set\n",
    "# You can now compare these predictions to the actual labels to compute your test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_iou(pred, target):\n",
    "    # Ensure the tensors are float type\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "\n",
    "    # Reshape the tensors to a 2D format\n",
    "    pred = pred.view(pred.shape[0], -1)\n",
    "    target = target.view(target.shape[0], -1)\n",
    "\n",
    "    # Calculate intersection and union for each sample\n",
    "    intersection = (pred * target).sum(dim=1)\n",
    "    union = (pred + target).clamp(0, 1).sum(dim=1)\n",
    "\n",
    "    # Calculate IoU and avoid division by zero\n",
    "    iou = intersection / (union + 1e-8)\n",
    "\n",
    "    return iou.mean()\n",
    "\n",
    "# Usage:\n",
    "# Assume `output` is the output of your model and `target` is your ground truth\n",
    "# Both `output` and `target` should be one-hot encoded and have the same shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t (10065,) \t [0 3 4 5] \t [0 1 2 3]\n",
      "\n",
      "1 \t (5704,) \t [0 3 4] \t [0 1 2]\n",
      "\n",
      "2 \t (14113,) \t [0] \t [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "3 \t (7083,) \t [0 3 4 6] \t [0 1 2 3 4 5]\n",
      "\n",
      "4 \t (10423,) \t [ 0  4  5  7 15] \t [0 1 2]\n",
      "\n",
      "5 \t (6830,) \t [0] \t [0 1 2 3 4 5 6]\n",
      "\n",
      "6 \t (6355,) \t [0] \t [0]\n",
      "\n",
      "7 \t (13648,) \t [0] \t [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      "8 \t (12394,) \t [0] \t [0 1 2 3 4 5 6]\n",
      "\n",
      "9 \t (7559,) \t [0 2 3 5 6 7] \t [0 1 2 3 4 5]\n",
      "\n",
      "10 \t (16444,) \t [0 6] \t [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "11 \t (6586,) \t [0 3 4 5 7] \t [0 1 2 3]\n",
      "\n",
      "12 \t (9898,) \t [0 6] \t [0 1 2 3]\n",
      "\n",
      "13 \t (8716,) \t [0 3] \t [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "14 \t (6429,) \t [ 0  3  6 11] \t [0 1 2 3 4 5 6 7 8]\n",
      "\n",
      "15 \t (15265,) \t [0 4 5 6 7] \t [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "16 \t (18205,) \t [0 3 6] \t [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n",
      "17 \t (13278,) \t [0 3 4 5] \t [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "18 \t (15318,) \t [0] \t [0 1 2 3 4 5 6 7]\n",
      "\n",
      "19 \t (6788,) \t [ 0  3  4  5  7 11] \t [0 1 2 3 4 5]\n",
      "\n",
      "20 \t (9654,) \t [0] \t [0 1 2]\n",
      "\n",
      "21 \t (5874,) \t [ 0  1  2  3  4  5  6  7 13] \t [0 1]\n",
      "\n",
      "22 \t (10569,) \t [0 3 4 6] \t [0 1 2 3 4 5 6]\n",
      "\n",
      "Mean iou score: 0.0941 \\pm 0.5770\n"
     ]
    }
   ],
   "source": [
    "iou_score = []\n",
    "for idx, (gt, pred) in enumerate(zip(ground_truth_labels, predictions)):\n",
    "    # Checking if the model predicts different labels for different points in the same point cloud\n",
    "    # if np.unique(pred).shape[0] != 1:\n",
    "    print(idx, \"\\t\", gt.shape, \"\\t\", np.unique(pred), \"\\t\", np.unique(gt))\n",
    "    print()\n",
    "    \n",
    "    iou_score.append(multi_label_iou(torch.tensor(pred), torch.tensor(gt)))\n",
    "    # accs.append(accuracy_score(gt, pred))\n",
    "    # f1s.append(f1_score(gt, pred, average='weighted'))\n",
    "\n",
    "print(f\"Mean iou score: {np.median(iou_score):.4f} \\pm {np.std(iou_score):.4f}\")\n",
    "#print(f\"Mean F!: {np.mean(f1s):.4f} \\pm {np.std(f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4688),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.6599),\n",
       " tensor(0.0941),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.),\n",
       " tensor(0.4552),\n",
       " tensor(0.),\n",
       " tensor(0.3246),\n",
       " tensor(0.),\n",
       " tensor(0.1332),\n",
       " tensor(2.2552),\n",
       " tensor(0.6352),\n",
       " tensor(0.0522),\n",
       " tensor(0.3759),\n",
       " tensor(0.),\n",
       " tensor(1.6120),\n",
       " tensor(0.),\n",
       " tensor(0.1180),\n",
       " tensor(1.2191)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6429, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list[14].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "i=13\n",
    "points = pos_list[i][ground_truth_labels[i] != 0]\n",
    "labels = ground_truth_labels[i][ground_truth_labels[i] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = label != -1\n",
    "# s0 = label == -1\n",
    "\n",
    "# x = halopartinfo[:, 0]\n",
    "# y = halopartinfo[:, 1]\n",
    "# z = halopartinfo[:, 2]\n",
    "# label = halopartinfo[:, -1]\n",
    "# # print(x.shape)\n",
    "\n",
    "# fig = go.Figure(data=[go.Scatter3d(\n",
    "#     x=x[s],\n",
    "#     y=y[s],\n",
    "#     z=z[s],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=4,\n",
    "#         color=label[s],\n",
    "#         colorscale='Rainbow',\n",
    "#         opacity=0.8\n",
    "#     )\n",
    "# ),\n",
    "#                       go.Scatter3d(\n",
    "#     x=x[s0],\n",
    "#     y=y[s0],\n",
    "#     z=z[s0],\n",
    "#     mode='markers',\n",
    "#     marker=dict(\n",
    "#         size=1,\n",
    "#         color=label[s0],\n",
    "#         colorscale='Viridis',\n",
    "#         opacity=0.5\n",
    "#     )\n",
    "# )\n",
    "# ])\n",
    "\n",
    "# fig.update_layout(margin=dict(l=0, r=0, b=0, t=0), width=1200, height=1000)\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=points[:,0],\n",
    "        y=points[:,1],\n",
    "        z=points[:,2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1, # Larger than surrounding data-points\n",
    "            color=labels,\n",
    "            opacity=0.75,\n",
    "            showscale=True,\n",
    "        ))\n",
    "])\n",
    "fig.update_layout(\n",
    "    title=f\"9898 points | BG: TODO: points\", title_x=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=pos_list[13][:,0],\n",
    "        y=pos_list[13][:,1],\n",
    "        z=pos_list[13][:,2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1, # Larger than surrounding data-points\n",
    "            color=predictions[13],\n",
    "            opacity=0.75,\n",
    "            showscale=True,\n",
    "        ))\n",
    "])\n",
    "fig.update_layout(\n",
    "    title=f\"{9898} points | BG: TODO: points\", title_x=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# np.unique(ground_truth_labels[0], return_counts=True)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39munique(ground_truth_labels[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: stop here"
     ]
    }
   ],
   "source": [
    "# np.unique(ground_truth_labels[0], return_counts=True)\n",
    "np.unique(ground_truth_labels[0]).shape\n",
    "raise NotImplementedError(\"stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(predictions[0], return_counts=True)\n",
    "np.unique(predictions[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this is meant to error out if left uncommented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, set):\n",
    "        if set == \"train\":\n",
    "            data = \"/home/group10/ml/Labeled subhalo matrices of haloes/train\"\n",
    "        elif set == \"val\":\n",
    "            data = \"/home/group10/ml/Labeled subhalo matrices of haloes/train/val\"\n",
    "        \n",
    "        self.length = len(data)\n",
    "\n",
    "        self.set = set\n",
    "        \n",
    "        files = os.listdir(data)\n",
    "        files = [torch.tensor(np.load(data+\"/\"+f), dtype=torch.float64) for f in files if f.endswith(\".npy\")]\n",
    "        files1=[f[:,:-1] for f in files]\n",
    "        self.files = files1\n",
    "        \n",
    "        labels = [f[:,-1] for f in files]\n",
    "        \n",
    "        labels = [torch.nn.functional.one_hot(j, 14) for j in labels]\n",
    "        \n",
    "        self.labels = labels\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return torch.tensor(self.files[index], dtype = torch.float64), torch.tensor(self.labels[index], dtype = torch.long)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "def train_accuracy(\n",
    "    model,\n",
    "    data_generator,\n",
    "    GPU = torch.device(\"cuda:2\"),\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        accs = []\n",
    "        for batch_x, batch_y in data_generator:\n",
    "            batch_x, batch_y = batch_x.to(GPU), batch_y\n",
    "            y_true = batch_y.argmax(1).numpy()\n",
    "            y_pred = model(batch_x).argmax(1).cpu().numpy()\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            accs.append(acc*100)\n",
    "    model.train()\n",
    "    return np.array(accs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    data = np.load(os.path.join(self.directory, self.files[idx]))\n",
    "    points = torch.tensor(data[:, :3], dtype=torch.float32)  # Assuming the first 3 columns are the point coordinates\n",
    "    labels = torch.tensor(data[:, 3:], dtype=torch.long)  # Assuming the rest of the columns are the labels\n",
    "    return points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def visualize_point_cloud(points, labels):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=labels, cmap='jet')\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of data\n",
    "data = next(iter(loader))\n",
    "\n",
    "# Run the model and get the outputs\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(data)\n",
    "\n",
    "# Get the predicted labels\n",
    "_, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "# Visualize the point cloud with the predicted labels\n",
    "visualize_point_cloud(data.pos.cpu().numpy(), predicted_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in loader:\n",
    "    print(data)\n",
    "    print(data.y.shape)\n",
    "    print(data.pos.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function expects dynamic number of classes\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "max_class_index = 0  # Initialize maximum class index\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Determine the maximum class index encountered\n",
    "        max_class_index = max(max_class_index, torch.max(data.y).item())\n",
    "        \n",
    "        # Adjust the fully connected layer dynamically based on the maximum class index\n",
    "        model.adjust_fc(max_class_index + 1)  # Add 1 to account for zero-based indexing\n",
    "        \n",
    "        loss = criterion(outputs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# After training, you can use the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(outputs.shape, data.y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
