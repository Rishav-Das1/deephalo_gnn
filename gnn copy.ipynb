{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_max_pool, knn_graph\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "# Set seed\n",
    "# SEED=42\n",
    "# random.seed(SEED)\n",
    "# torch.manual_seed(SEED)\n",
    "# np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetInstanceSeg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetInstanceSeg, self).__init__()\n",
    "        self.edge_conv1 = DynamicEdgeConv(nn.Sequential(\n",
    "            nn.Linear(14, 64),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.SiLU()\n",
    "        ), k=K)\n",
    "        self.edge_conv2 = DynamicEdgeConv(nn.Sequential(\n",
    "             nn.Linear(256, 128),\n",
    "             nn.SiLU(),\n",
    "             nn.Linear(128, 64),\n",
    "             nn.SiLU()\n",
    "         ), k=K)\n",
    "        # self.edge_conv3 = DynamicEdgeConv(nn.Sequential(\n",
    "        #      nn.Linear(1024, 512),\n",
    "        #      nn.SiLU(),\n",
    "        #      nn.Linear(512, 256),\n",
    "        #      nn.SiLU()\n",
    "        #  ), k=8)\n",
    "        # self.edge_conv4 = DynamicEdgeConv(nn.Sequential(\n",
    "        #      nn.Linear(256, 256),\n",
    "        #      nn.SiLU(),\n",
    "        #      nn.Linear(256, 128),\n",
    "        #      nn.SiLU()\n",
    "        #  ), k=K)\n",
    "        self.fc = nn.Linear(64, 21)  # Predicting instance mask for each point\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.pos, data.edge_index\n",
    "        # print(data.edge_index)\n",
    "        # return\n",
    "        x = self.edge_conv1(x, edge_index)\n",
    "        x = self.edge_conv2(x, edge_index)\n",
    "        # x = self.edge_conv3(x, edge_index)\n",
    "        # x = self.edge_conv4(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Calc number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(PointNetInstanceSeg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/home/group10/deephalo_gnn/Imbalance_Resampled_for_mulltilabel/train\"\n",
    "files = os.listdir(data)\n",
    "point_cloud_data = [(np.load(data+\"/\"+f)) for f in files if f.endswith(\".npy\")] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the features\n",
    "    pos = torch.tensor(point_cloud[:,:-1], dtype=torch.float)\n",
    "    # Recentering positions per halo\n",
    "    pos[:3] = pos[:3] - pos[:3].mean(dim=1, keepdim=True)\n",
    "    data = Data(\n",
    "        pos=pos,\n",
    "        y = torch.eye(21)[torch.tensor(point_cloud[:,-1]+1, dtype=torch.long)],\n",
    "        \n",
    "    )\n",
    "    \n",
    "    data_list.append(data)\n",
    "\n",
    "# Now you can use DataLoader with this list of Data objects\n",
    "loader = DataLoader(data_list, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y\n",
    "print(data.y)\n",
    "class_labels = torch.argmax(data.y, dim=1)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for point_clouds in point_cloud_data:\n",
    "    label = point_clouds[:,-1]\n",
    "    labels.append(label)\n",
    "labels = torch.tensor(np.concatenate(labels))\n",
    "\n",
    "# Calculate unique labels and counts\n",
    "unique_labels, counts = torch.unique(labels, return_counts=True)\n",
    "\n",
    "# Calculate frequencies\n",
    "frequencies = counts.float() / labels.numel()\n",
    "\n",
    "# Calculate weights\n",
    "weight_vec = 1.0 / torch.log(torch.tensor(1.2) + frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vec[0]=0.01\n",
    "weight_vec\n",
    "weight_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1., gamma=2.):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce_logits = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = self.bce_logits(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNetInstanceSeg().to(DEVICE)\n",
    "weights = torch.FloatTensor(weight_vec).to(DEVICE)\n",
    "\n",
    "\n",
    "criterion = FocalLoss(alpha=weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data.to(DEVICE)\n",
    "        # print(data.y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Create the \"ckpts\" directory if it doesn't exist\n",
    "import os, time\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "curr_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"{curr_time}_pointnet_instance_seg\"\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f\"./ckpts/{model_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = \"/home/group10/deephalo_gnn/Labeled subhalo matrices of haloes/test\"\n",
    "files = os.listdir(data_test)\n",
    "point_cloud_data = [(np.load(data_test+\"/\"+f)) for f in files if f.endswith(\".npy\") and (int(f[:-4])>50)] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_test_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the features\n",
    "    data_test = Data(pos=torch.tensor(point_cloud[:,:-1], dtype=torch.float), y = torch.eye(21)[torch.tensor(point_cloud[:,-1]+1, dtype=torch.long)])\n",
    "    data_test_list.append(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(data_test_list, batch_size=1, shuffle=False)\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions\n",
    "ground_truth_labels = []\n",
    "predictions = []\n",
    "pos_list = []\n",
    "\n",
    "# Loop over the test data\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        # Move data to the device\n",
    "        data = data.to(DEVICE)\n",
    "        \n",
    "        # Pass the data through the model\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Get the predicted labels\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        _, ground_truth = torch.max(data.y, 1)\n",
    "        pos = data.pos.cpu().numpy()\n",
    "        pos = pos[:,0:3]\n",
    "        # Store the predictions\n",
    "        ground_truth_labels.append(ground_truth.cpu().numpy())\n",
    "        predictions.append(predicted_labels.cpu().numpy())\n",
    "        pos_list.append(pos)\n",
    "    \n",
    "\n",
    "# At this point, `predictions` is a list of numpy arrays with the predicted labels for each point cloud in the test set\n",
    "# You can now compare these predictions to the actual labels to compute your test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_iou(pred, target):\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "\n",
    "    # Reshape the tensors to a 2D format\n",
    "    pred = pred.view(pred.shape[0], -1)\n",
    "    target = target.view(target.shape[0], -1)\n",
    "\n",
    "    # Calculate intersection and union for each sample\n",
    "    intersection = (pred * target).sum(dim=1)\n",
    "    union = (pred + target).clamp(0, 1).sum(dim=1)\n",
    "\n",
    "    # Calculate IoU and avoid division by zero\n",
    "    iou = intersection / (union + 1e-8)\n",
    "\n",
    "    return iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid = 14\n",
    "\n",
    "# tar, masked = self.prep_tar(hid)\n",
    "# num_masked = sum(masked)\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter3d(\n",
    "        x=pos_list[hid][:,0],\n",
    "        y=pos_list[hid][:,1],\n",
    "        z=pos_list[hid][:,2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1, # Larger than surrounding data-points\n",
    "            color=ground_truth_labels[hid],\n",
    "            opacity=0.75,\n",
    "            showscale=True,\n",
    "        ))\n",
    "])\n",
    "fig.update_layout(\n",
    "    title=f'{predictions[hid].shape} particles', title_x=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_score = []\n",
    "for idx, (gt, pred) in enumerate(zip(ground_truth_labels, predictions)):\n",
    "    # Checking if the model predicts different labels for different points in the same point cloud\n",
    "    # if np.unique(pred).shape[0] != 1:\n",
    "    print(idx, \"\\t\", gt.shape, \"\\t\", np.unique(pred), \"\\t\", np.unique(gt))\n",
    "    print()\n",
    "    \n",
    "    iou_score.append(multi_label_iou(torch.tensor(pred), torch.tensor(gt)))\n",
    "\n",
    "print(f\"Mean acc: {np.mean(iou_score):.4f} \\pm {np.std(iou_score):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
