{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_max_pool, knn_graph\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PointNetInstanceSeg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetInstanceSeg, self).__init__()\n",
    "        self.edge_conv1 = DynamicEdgeConv(nn.Sequential(\n",
    "            nn.Linear(14, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.SiLU(),\n",
    "        ), k=K)\n",
    "        self.edge_conv2 = DynamicEdgeConv(nn.Sequential(\n",
    "              nn.Linear(124, 64),\n",
    "              nn.SiLU(),\n",
    "          ), k=K)\n",
    "        # self.edge_conv3 = DynamicEdgeConv(nn.Sequential(\n",
    "        #       nn.Linear(256, 128),\n",
    "        #       nn.SiLU(),\n",
    "        #       nn.Linear(128, 64),\n",
    "        #       nn.SiLU()\n",
    "        #   ), k=K)\n",
    "        # self.edge_conv4 = DynamicEdgeConv(nn.Sequential(\n",
    "        #       nn.Linear(256, 128),\n",
    "        #       nn.SiLU(),\n",
    "        #       nn.Linear(128, 64),\n",
    "        #       nn.SiLU()\n",
    "        #   ), k=K)\n",
    "        self.fc = nn.Linear(64, 2)  # Predicting instance mask for each point\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.pos, data.edge_index\n",
    "        # print(data.edge_index)\n",
    "        # return\n",
    "        x = self.edge_conv1(x, edge_index)\n",
    "        x = self.edge_conv2(x, edge_index)\n",
    "        # x = self.edge_conv3(x, edge_index)\n",
    "        # x = self.edge_conv4(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # def adjust_fc(self, num_classes):\n",
    "    #     self.fc = nn.Linear(128, num_classes = 2)\n",
    "\n",
    "\n",
    "\n",
    "# Calc number of trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(PointNetInstanceSeg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = \"/home/group10/deephalo_gnn/BinaryLabeledData/train\"\n",
    "files = os.listdir(data)\n",
    "point_cloud_data = [(np.load(data+\"/\"+f)) for f in files if f.endswith(\".npy\")] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the positions of points\n",
    "    pos = torch.tensor(point_cloud[:,:-1], dtype=torch.float)\n",
    "    # Recentering positions per halo\n",
    "    pos[:3] = pos[:3] - pos[:3].mean(dim=1, keepdim=True)\n",
    "    data = Data(\n",
    "        pos=pos,\n",
    "        y = torch.eye(2)[torch.tensor(point_cloud[:,-1], dtype=torch.long)],\n",
    "        #edge_index=knn_graph(pos, k=K)\n",
    "    )\n",
    "    \n",
    "    data_list.append(data)\n",
    "\n",
    "# Now you can use DataLoader with this list of Data objects\n",
    "loader = DataLoader(data_list, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_vec=np.array([0.000000000001,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vec[0]/weight_vec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define your dataset and DataLoader\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dataloader = DataLoader(SHDataSet(\"train\"), batch_size=1, shuffle=True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPointNetInstanceSeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(weight_vec)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define your loss function and optimizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Assuming instance masks are represented as class labels\u001b[39;00m\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/deephalo_gnn/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define your dataset and DataLoader\n",
    "# Initialize the model\n",
    "model = PointNetInstanceSeg().to(DEVICE)\n",
    "weights = torch.FloatTensor(weight_vec).to(DEVICE)\n",
    "# Define your loss function and optimizer\n",
    "# Assuming instance masks are represented as class labels\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(weight=weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        data.to(DEVICE)\n",
    "        # print(data.y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        # Assuming instance masks are represented as class labels and provided in data.y\n",
    "        # target = torch.argmax(data.y, dim=1)  # Convert one-hot encoded target to class labels\n",
    "        # loss = criterion(outputs, target)\n",
    "        loss = criterion(outputs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Create the \"ckpts\" directory if it doesn't exist\n",
    "import os, time\n",
    "\n",
    "os.makedirs(\"ckpts\", exist_ok=True)\n",
    "curr_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"{curr_time}_pointnet_instance_seg\"\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), f\"./ckpts/{model_name}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = \"/home/group10/deephalo_gnn/BinaryLabeledData/test\"\n",
    "files = os.listdir(data_test)\n",
    "point_cloud_data = [(np.load(data_test+\"/\"+f)) for f in files if f.endswith(\".npy\")] # List of point cloud data, each element is a list of point coordinates\n",
    "\n",
    "# Convert each point cloud data into a Data object\n",
    "data_test_list = []\n",
    "for point_cloud in point_cloud_data:\n",
    "    # Create a Data object with the positions of points\n",
    "    data_test = Data(pos=torch.tensor(point_cloud[:,:-1], dtype=torch.float), y = torch.eye(2)[torch.tensor(point_cloud[:,-1], dtype=torch.long)])\n",
    "    \n",
    "    data_test_list.append(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 30/30 [00:02<00:00, 10.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = DataLoader(data_test_list, batch_size=1, shuffle=False)\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions\n",
    "ground_truth_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Loop over the test data\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing'):\n",
    "        # Move data to the device\n",
    "        data = data.to(DEVICE)\n",
    "        \n",
    "        # Pass the data through the model\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Get the predicted labels\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        \n",
    "        # Store the predictions\n",
    "        ground_truth_labels.append(data.y.cpu().numpy())\n",
    "        predictions.append(predicted_labels.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t (8668, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "1 \t (176809, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "2 \t (7641, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "3 \t (5704, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "4 \t (7083, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "5 \t (10423, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "6 \t (31397, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "7 \t (9118, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "8 \t (38128, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "9 \t (13188, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "10 \t (12394, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "11 \t (9524, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "12 \t (7714, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "13 \t (12774, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "14 \t (8716, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "15 \t (5366, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "16 \t (13644, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "17 \t (18205, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "18 \t (15889, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "19 \t (7831, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "20 \t (69640, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "21 \t (14424, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "22 \t (5642, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "23 \t (90050, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "24 \t (22845, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "25 \t (5874, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "26 \t (16718, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "27 \t (10287, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "28 \t (10569, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "29 \t (5575, 2) \t [0] \t [0. 1.]\n",
      "\n",
      "Mean acc: nan \\pm nan\n",
      "Mean F!: nan \\pm nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accs = []\n",
    "f1s = []\n",
    "for idx, (gt, pred) in enumerate(zip(ground_truth_labels, predictions)):\n",
    "    # Checking if the model predicts different labels for different points in the same point cloud\n",
    "    # if np.unique(pred).shape[0] != 1:\n",
    "    print(idx, \"\\t\", gt.shape, \"\\t\", np.unique(pred), \"\\t\", np.unique(gt))\n",
    "    print()\n",
    "    \n",
    "    # accs.append(accuracy_score(gt, pred))\n",
    "    # f1s.append(f1_score(gt, pred, average='weighted'))\n",
    "\n",
    "print(f\"Mean acc: {np.mean(accs):.4f} \\pm {np.std(accs):.4f}\")\n",
    "print(f\"Mean F!: {np.mean(f1s):.4f} \\pm {np.std(f1s):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
